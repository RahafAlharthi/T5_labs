{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahafAlharthi/T5_labs/blob/main/OCR_Using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f029bf03",
      "metadata": {
        "id": "f029bf03"
      },
      "source": [
        "# OCR Application Using CNN on MNIST Dataset\n",
        "This notebook demonstrates how to apply Convolutional Neural Networks (CNN) for Optical Character Recognition (OCR). We will be working with the MNIST dataset, which contains images of handwritten digits. The goal is to build an OCR system that can accurately classify these digits using deep learning with CNN.\n",
        "We will:\n",
        "1. Load and preprocess the dataset\n",
        "2. Build and train a CNN model\n",
        "3. Make predictions on new images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45192701",
      "metadata": {
        "id": "45192701"
      },
      "source": [
        "## Step 1: Import Libraries\n",
        "Let's start by importing the necessary libraries for building and training our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4d8100c",
      "metadata": {
        "id": "d4d8100c"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbfc2a04",
      "metadata": {
        "id": "fbfc2a04"
      },
      "source": [
        "## Step 2: Load and Preprocess the MNIST Dataset\n",
        "We will now load the MNIST dataset, reshape it to fit the input of our CNN model, and normalize the data to be in the range [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a283f1dc",
      "metadata": {
        "id": "a283f1dc",
        "outputId": "e5e4a0aa-e054-4d98-8b70-5f34414a80ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshaping and normalizing\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4136658c",
      "metadata": {
        "id": "4136658c"
      },
      "source": [
        "## Step 3: Build the CNN Model\n",
        "We'll define a simple CNN model with the following layers:\n",
        "- Convolutional layers for feature extraction\n",
        "- MaxPooling for downsampling\n",
        "- Dropout layers to prevent overfitting\n",
        "- Dense layers for final classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76643ee9",
      "metadata": {
        "id": "76643ee9",
        "outputId": "2c70ef04-3204-4e0b-9576-636a2aa442d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842ca22a",
      "metadata": {
        "id": "842ca22a"
      },
      "source": [
        "## Step 4: Compile and Train the Model\n",
        "Next, we'll compile our model using categorical cross-entropy as the loss function, Adadelta as the optimizer, and accuracy as the metric.\n",
        "After compiling, we'll train the model on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a9c21872",
      "metadata": {
        "id": "a9c21872",
        "outputId": "6b49dd0b-fbae-42b5-fb9a-e08eb9d9659e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.1024 - loss: 2.3011 - val_accuracy: 0.2516 - val_loss: 2.2413\n",
            "Epoch 2/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2114 - loss: 2.2370 - val_accuracy: 0.4704 - val_loss: 2.1621\n",
            "Epoch 3/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.3168 - loss: 2.1600 - val_accuracy: 0.5781 - val_loss: 2.0605\n",
            "Epoch 4/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.4045 - loss: 2.0632 - val_accuracy: 0.6344 - val_loss: 1.9285\n",
            "Epoch 5/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4781 - loss: 1.9374 - val_accuracy: 0.6841 - val_loss: 1.7625\n",
            "Epoch 6/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 1.7812 - val_accuracy: 0.7189 - val_loss: 1.5744\n",
            "Epoch 7/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5791 - loss: 1.6237 - val_accuracy: 0.7455 - val_loss: 1.3824\n",
            "Epoch 8/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6107 - loss: 1.4613 - val_accuracy: 0.7679 - val_loss: 1.2037\n",
            "Epoch 9/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6356 - loss: 1.3239 - val_accuracy: 0.7858 - val_loss: 1.0540\n",
            "Epoch 10/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6599 - loss: 1.2066 - val_accuracy: 0.7985 - val_loss: 0.9334\n",
            "Epoch 11/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6760 - loss: 1.1134 - val_accuracy: 0.8106 - val_loss: 0.8396\n",
            "Epoch 12/12\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6912 - loss: 1.0366 - val_accuracy: 0.8230 - val_loss: 0.7655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79c30f789330>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=12,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "294ccec8",
      "metadata": {
        "id": "294ccec8"
      },
      "source": [
        "## Step 5: Visualizing Random Predictions from the Test Set\n",
        "Finally, let's visualize a random image from the test set along with the model's prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4a9443c",
      "metadata": {
        "id": "a4a9443c",
        "outputId": "661ca472-cf4e-47fa-a2b6-14a3d09f35d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Select a random image\n",
        "random_idx = random.randint(0, x_test.shape[0] - 1)\n",
        "random_image = x_test[random_idx]\n",
        "\n",
        "# Get the model's prediction\n",
        "predicted_label = model.predict(random_image.reshape(1, 28, 28, 1)).argmax()\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(random_image.squeeze(), cmap='gray')\n",
        "plt.title(f'Model Prediction: {predicted_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}